{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import numpy as np\n",
    "import math\n",
    "from numpy import arange\n",
    "from matplotlib import pyplot\n",
    "%matplotlib inline\n",
    "from pandas import read_csv\n",
    "from pandas import set_option\n",
    "from pandas.tools.plotting import scatter_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "from sklearn.metrics import make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load Dataset\n",
    "dataset = read_csv('train_bikes.csv')\n",
    "dataset.datetime = dataset.datetime.apply(pd.to_datetime)\n",
    "dataset['year'] = dataset.datetime.apply(lambda x : x.year)\n",
    "dataset['month'] = dataset.datetime.apply(lambda x : x.month)\n",
    "dataset['hour'] = dataset.datetime.apply(lambda x : x.hour)\n",
    "dataset['dayofweek'] = dataset.datetime.apply(lambda x : x.dayofweek)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6531L, 12L)\n",
      "(4355L, 12L)\n"
     ]
    }
   ],
   "source": [
    "# Prepare Data\n",
    "Y = dataset['count'].values\n",
    "Y = np.log(Y)\n",
    "X = dataset[dataset.columns[1:].drop(['casual','registered','count'])].values\n",
    "validation_size = 0.4\n",
    "seed = 27\n",
    "X_train, X_validation, Y_train, Y_validation = train_test_split(X, Y, test_size=validation_size, random_state=seed)\n",
    "print X_train.shape\n",
    "print X_validation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test options and evaluation metric\n",
    "num_folds = 5\n",
    "seed = 27\n",
    "scoring1 = 'neg_mean_squared_error'\n",
    "scoring2 = 'neg_mean_absolute_error'\n",
    "scoring3 = 'r2'\n",
    "def rmsle(y, y_preds): #define new metric\n",
    "    log1 = np.nan_to_num(np.array([np.log(v + 1) for v in y]))\n",
    "    log2 = np.nan_to_num(np.array([np.log(v + 1) for v in y_preds]))\n",
    "    calc = (log1 - log2) ** 2\n",
    "    return np.sqrt(np.mean(calc))\n",
    "rmsle_scorer = make_scorer(rmsle, greater_is_better=False)#create scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Evaluate Algorithms\n",
    "# Spot Check Algorithms\n",
    "models = []\n",
    "models.append(('LR', LinearRegression()))\n",
    "models.append(('LASSO', Lasso()))\n",
    "models.append(('EN', ElasticNet()))\n",
    "models.append(('RIDGE', Ridge()))\n",
    "models.append(('KNN', KNeighborsRegressor()))\n",
    "models.append(('CART', DecisionTreeRegressor()))\n",
    "models.append(('SVR', SVR()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: -0.268945 (0.017580)\n",
      "LASSO: -0.284852 (0.019090)\n",
      "EN: -0.279281 (0.018531)\n",
      "RIDGE: -0.268945 (0.017581)\n",
      "KNN: -0.226128 (0.015326)\n",
      "CART: -0.151184 (0.010000)\n",
      "SVR: -0.269929 (0.021581)\n"
     ]
    }
   ],
   "source": [
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    kfold = KFold(n_splits=num_folds, random_state=seed)\n",
    "    cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring=rmsle_scorer)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    rmsle = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(rmsle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ScaledLR: -0.268945 (0.017580)\n",
      "ScaledLASSO: -0.356256 (0.019768)\n",
      "ScaledEN: -0.334449 (0.020376)\n",
      "ScaledKNN: -0.245575 (0.017221)\n",
      "ScaledCART: -0.154556 (0.012115)\n",
      "ScaledSVR: -0.241090 (0.017358)\n"
     ]
    }
   ],
   "source": [
    "# Standardize the dataset/StandardScaler\n",
    "pipelines = []\n",
    "pipelines.append(('ScaledLR', Pipeline([('Scaler', StandardScaler()),('LR', LinearRegression())])))\n",
    "pipelines.append(('ScaledLASSO', Pipeline([('Scaler', StandardScaler()),('LASSO', Lasso())])))\n",
    "pipelines.append(('ScaledEN', Pipeline([('Scaler', StandardScaler()),('EN', ElasticNet())])))\n",
    "pipelines.append(('ScaledKNN', Pipeline([('Scaler', StandardScaler()),('KNN', KNeighborsRegressor())])))\n",
    "pipelines.append(('ScaledCART', Pipeline([('Scaler', StandardScaler()),('CART', DecisionTreeRegressor())])))\n",
    "pipelines.append(('ScaledSVR', Pipeline([('Scaler', StandardScaler()),('SVR', SVR())])))\n",
    "results = []\n",
    "names = []\n",
    "for name, model in pipelines:\n",
    "    kfold = KFold(n_splits=num_folds, random_state=seed)\n",
    "    cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring=rmsle_scorer)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ScaledLR: -0.268945 (0.017580)\n",
      "ScaledLASSO: -0.356256 (0.019768)\n",
      "ScaledEN: -0.356256 (0.019768)\n",
      "ScaledKNN: -0.224350 (0.013779)\n",
      "ScaledCART: -0.151433 (0.009275)\n",
      "ScaledSVR: -0.264631 (0.018741)\n"
     ]
    }
   ],
   "source": [
    "# Standardize the dataset/MinMaxScaler\n",
    "pipelinesM = []\n",
    "pipelinesM.append(('ScaledLR', Pipeline([('Scaler', MinMaxScaler()),('LR', LinearRegression())])))\n",
    "pipelinesM.append(('ScaledLASSO', Pipeline([('Scaler', MinMaxScaler()),('LASSO', Lasso())])))\n",
    "pipelinesM.append(('ScaledEN', Pipeline([('Scaler', MinMaxScaler()),('EN', ElasticNet())])))\n",
    "pipelinesM.append(('ScaledKNN', Pipeline([('Scaler', MinMaxScaler()),('KNN', KNeighborsRegressor())])))\n",
    "pipelinesM.append(('ScaledCART', Pipeline([('Scaler', MinMaxScaler()),('CART', DecisionTreeRegressor())])))\n",
    "pipelinesM.append(('ScaledSVR', Pipeline([('Scaler', MinMaxScaler()),('SVR', SVR())])))\n",
    "resultsM = []\n",
    "namesM = []\n",
    "for name, model in pipelinesM:\n",
    "    kfold = KFold(n_splits=num_folds, random_state=seed)\n",
    "    cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring=rmsle_scorer)\n",
    "    resultsM.append(cv_results)\n",
    "    namesM.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAESCAYAAAAVLtXjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngP4/Qae29XtoUMkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xaa20668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compare Algorithms\n",
    "fig = pyplot.figure()\n",
    "fig.suptitle('Scaled Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "pyplot.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAESCAYAAAAVLtXjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhP4/8jKXdli0WkwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x70ee9e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compare Algorithms\n",
    "fig = pyplot.figure()\n",
    "fig.suptitle('ScaledMinMax Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "pyplot.boxplot(resultsM)\n",
    "ax.set_xticklabels(namesM)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ScaledAB: -0.170170 (0.010538)\n",
      "ScaledGBM: -0.125823 (0.010177)\n",
      "ScaledRF: -0.118294 (0.007368)\n",
      "ScaledET: -0.119599 (0.011145)\n"
     ]
    }
   ],
   "source": [
    "# ensembles/Standard\n",
    "ensembles = []\n",
    "ensembles.append(('ScaledAB', Pipeline([('Scaler', StandardScaler()),('AB', AdaBoostRegressor(random_state=seed))])))\n",
    "ensembles.append(('ScaledGBM', Pipeline([('Scaler', StandardScaler()),('GBM', GradientBoostingRegressor(random_state=seed))])))\n",
    "ensembles.append(('ScaledRF', Pipeline([('Scaler', StandardScaler()),('RF', RandomForestRegressor(random_state=seed))])))\n",
    "ensembles.append(('ScaledET', Pipeline([('Scaler', StandardScaler()),('ET', ExtraTreesRegressor(random_state=seed))])))\n",
    "results_ens = []\n",
    "names_ens = []\n",
    "for name, model in ensembles:\n",
    "    kfold = KFold(n_splits=num_folds, random_state=seed)\n",
    "    cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring=rmsle_scorer)\n",
    "    results_ens.append(cv_results)\n",
    "    names_ens.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ScaledAB: -0.170170 (0.010538)\n",
      "ScaledGBM: -0.125823 (0.010177)\n",
      "ScaledRF: -0.118294 (0.007368)\n",
      "ScaledET: -0.119599 (0.011145)\n"
     ]
    }
   ],
   "source": [
    "# ensembles/MinMax\n",
    "ensemblesM = []\n",
    "ensemblesM.append(('ScaledAB', Pipeline([('Scaler', MinMaxScaler()),('AB', AdaBoostRegressor(random_state=seed))])))\n",
    "ensemblesM.append(('ScaledGBM', Pipeline([('Scaler', MinMaxScaler()),('GBM', GradientBoostingRegressor(random_state=seed))])))\n",
    "ensemblesM.append(('ScaledRF', Pipeline([('Scaler', MinMaxScaler()),('RF', RandomForestRegressor(random_state=seed))])))\n",
    "ensemblesM.append(('ScaledET', Pipeline([('Scaler', MinMaxScaler()),('ET', ExtraTreesRegressor(random_state=seed))])))\n",
    "results_ensM = []\n",
    "names_ensM = []\n",
    "for name, model in ensembles:\n",
    "    kfold = KFold(n_splits=num_folds, random_state=seed)\n",
    "    cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring=rmsle_scorer)\n",
    "    results_ensM.append(cv_results)\n",
    "    names_ensM.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.337386558628\n"
     ]
    }
   ],
   "source": [
    "ensembles[2][1].fit(X_train,Y_train)\n",
    "preds = ensembles[2][1].predict(X_validation)\n",
    "print rmsle(np.exp(Y_validation), np.exp(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: -0.112830 using {'max_features': 0.80000000000000004, 'n_estimators': 500}\n",
      "-0.140486 (0.013480) with: {'max_features': 0.29999999999999999, 'n_estimators': 500}\n",
      "-0.128279 (0.012411) with: {'max_features': 0.40000000000000002, 'n_estimators': 500}\n",
      "-0.117461 (0.010356) with: {'max_features': 0.5, 'n_estimators': 500}\n",
      "-0.114935 (0.009628) with: {'max_features': 0.59999999999999998, 'n_estimators': 500}\n",
      "-0.113620 (0.009076) with: {'max_features': 0.69999999999999996, 'n_estimators': 500}\n",
      "-0.112830 (0.008950) with: {'max_features': 0.80000000000000004, 'n_estimators': 500}\n"
     ]
    }
   ],
   "source": [
    "# Tune scaled RF\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "rescaledX = scaler.transform(X_train)\n",
    "param_grid = dict(n_estimators=np.array([500]),max_features = np.array([0.3,0.4,0.5,0.6,0.7,0.8]))\n",
    "model = RandomForestRegressor(random_state=seed)\n",
    "kfold = KFold(n_splits=num_folds, random_state=seed)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring=rmsle_scorer, cv=kfold)\n",
    "grid_result = grid.fit(rescaledX, Y_train)\n",
    "\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: -0.112941 using {'max_features': 0.80000000000000004, 'n_estimators': 1000}\n",
      "-0.117174 (0.010197) with: {'max_features': 0.5, 'n_estimators': 1000}\n",
      "-0.114734 (0.009546) with: {'max_features': 0.65000000000000002, 'n_estimators': 1000}\n",
      "-0.112941 (0.008981) with: {'max_features': 0.80000000000000004, 'n_estimators': 1000}\n"
     ]
    }
   ],
   "source": [
    "# Tune scaled RF\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "rescaledX = scaler.transform(X_train)\n",
    "param_grid = dict(n_estimators=np.array([1000]),max_features = np.array([0.5,0.65,0.8]))\n",
    "model = RandomForestRegressor(random_state=seed)\n",
    "kfold = KFold(n_splits=num_folds, random_state=seed)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring=rmsle_scorer, cv=kfold)\n",
    "grid_result = grid.fit(rescaledX, Y_train)\n",
    "\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: -0.112900 using {'max_features': 0.80000000000000004, 'n_estimators': 2000, 'max_depth': 50}\n",
      "-0.113142 (0.009021) with: {'max_features': 0.80000000000000004, 'n_estimators': 1000, 'max_depth': 20}\n",
      "-0.113030 (0.008957) with: {'max_features': 0.80000000000000004, 'n_estimators': 2000, 'max_depth': 20}\n",
      "-0.112941 (0.008981) with: {'max_features': 0.80000000000000004, 'n_estimators': 1000, 'max_depth': 50}\n",
      "-0.112900 (0.008968) with: {'max_features': 0.80000000000000004, 'n_estimators': 2000, 'max_depth': 50}\n",
      "-0.112941 (0.008981) with: {'max_features': 0.80000000000000004, 'n_estimators': 1000, 'max_depth': 100}\n",
      "-0.112900 (0.008968) with: {'max_features': 0.80000000000000004, 'n_estimators': 2000, 'max_depth': 100}\n"
     ]
    }
   ],
   "source": [
    "# Tune scaled RF\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "rescaledX = scaler.transform(X_train)\n",
    "param_grid = dict(n_estimators=np.array([1000, 2000]), max_depth = np.array([20,50,100]), max_features = np.array([0.8]))\n",
    "model = RandomForestRegressor(random_state=seed)\n",
    "kfold = KFold(n_splits=num_folds, random_state=seed)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring=rmsle_scorer, cv=kfold)\n",
    "grid_result = grid.fit(rescaledX, Y_train)\n",
    "\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.311348806385\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler().fit(X_train)\n",
    "rescaledX = scaler.transform(X_train)\n",
    "model = RandomForestRegressor(random_state=seed, n_estimators = 2000, max_depth = 50, max_features=0.8)\n",
    "model.fit(rescaledX,Y_train)\n",
    "rescaledValidationX = scaler.transform(X_validation)\n",
    "preds = model.predict(rescaledValidationX)\n",
    "\n",
    "print rmsle(np.exp(Y_validation), np.exp(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: -0.109410 using {'max_features': 0.59999999999999998, 'n_estimators': 500}\n",
      "-0.116914 (0.006679) with: {'max_features': 0.29999999999999999, 'n_estimators': 500}\n",
      "-0.112845 (0.008878) with: {'max_features': 0.40000000000000002, 'n_estimators': 500}\n",
      "-0.111343 (0.007354) with: {'max_features': 0.5, 'n_estimators': 500}\n",
      "-0.109410 (0.007435) with: {'max_features': 0.59999999999999998, 'n_estimators': 500}\n",
      "-0.111937 (0.007006) with: {'max_features': 0.69999999999999996, 'n_estimators': 500}\n",
      "-0.110765 (0.008118) with: {'max_features': 0.80000000000000004, 'n_estimators': 500}\n"
     ]
    }
   ],
   "source": [
    "# Tune scaled GB\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "rescaledX = scaler.transform(X_train)\n",
    "param_grid = dict(n_estimators = np.array([500]), max_features = np.array([0.3,0.4,0.5,0.6,0.7,0.8]))\n",
    "model = GradientBoostingRegressor(random_state=seed)\n",
    "kfold = KFold(n_splits=num_folds, random_state=seed)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring=rmsle_scorer, cv=kfold)\n",
    "grid_result = grid.fit(rescaledX, Y_train)\n",
    "\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: -0.111021 using {'max_features': 0.59999999999999998, 'n_estimators': 2000, 'learning_rate': 0.14999999999999999}\n",
      "-0.112419 (0.009646) with: {'max_features': 0.59999999999999998, 'n_estimators': 2000, 'learning_rate': 0.10000000000000001}\n",
      "-0.111021 (0.008331) with: {'max_features': 0.59999999999999998, 'n_estimators': 2000, 'learning_rate': 0.14999999999999999}\n",
      "-0.112298 (0.008861) with: {'max_features': 0.59999999999999998, 'n_estimators': 2000, 'learning_rate': 0.20000000000000001}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:9: RuntimeWarning: invalid value encountered in log\n"
     ]
    }
   ],
   "source": [
    "# Tune scaled GB\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "rescaledX = scaler.transform(X_train)\n",
    "param_grid = dict(learning_rate=np.array([0.1, 0.15,0.2]), n_estimators = np.array([2000]), max_features = np.array([0.6]))\n",
    "model = GradientBoostingRegressor(random_state=seed)\n",
    "kfold = KFold(n_splits=num_folds, random_state=seed)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring=rmsle_scorer, cv=kfold)\n",
    "grid_result = grid.fit(rescaledX, Y_train)\n",
    "\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.285803478662\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler().fit(X_train)\n",
    "rescaledX = scaler.transform(X_train)\n",
    "model = GradientBoostingRegressor(random_state=seed, n_estimators = 2500, learning_rate = 0.08,  max_features=0.5)\n",
    "model.fit(rescaledX,Y_train)\n",
    "rescaledValidationX = scaler.transform(X_validation)\n",
    "preds = model.predict(rescaledValidationX)\n",
    "\n",
    "print rmsle(np.exp(Y_validation), np.exp(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: -0.111439 using {'n_estimators': 700}\n",
      "-0.112350 (0.009652) with: {'n_estimators': 100}\n",
      "-0.111628 (0.010042) with: {'n_estimators': 250}\n",
      "-0.111461 (0.010045) with: {'n_estimators': 400}\n",
      "-0.111439 (0.010141) with: {'n_estimators': 700}\n",
      "-0.111455 (0.010138) with: {'n_estimators': 1000}\n"
     ]
    }
   ],
   "source": [
    "# Tune scaled ET\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "rescaledX = scaler.transform(X_train)\n",
    "param_grid = dict(n_estimators=np.array([100, 250, 400, 700, 1000]))\n",
    "model = ExtraTreesRegressor(random_state=seed, oob_score=True, bootstrap=True)\n",
    "kfold = KFold(n_splits=num_folds, random_state=seed)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring=rmsle_scorer, cv=kfold)\n",
    "grid_result = grid.fit(rescaledX, Y_train)\n",
    "\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.296937244423\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler().fit(X_train)\n",
    "rescaledX = scaler.transform(X_train)\n",
    "model = ExtraTreesRegressor(random_state=seed, n_estimators = 700, oob_score=True, bootstrap=True)\n",
    "model.fit(rescaledX,Y_train)\n",
    "rescaledValidationX = scaler.transform(X_validation)\n",
    "preds = model.predict(rescaledValidationX)\n",
    "\n",
    "print rmsle(np.exp(Y_validation), np.exp(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.319779537097\n"
     ]
    }
   ],
   "source": [
    "#just a try ( ;-)\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "rescaledX = scaler.transform(X_train)\n",
    "model = AdaBoostRegressor(random_state=seed,base_estimator = RandomForestRegressor(random_state=seed, n_estimators = 100, \n",
    "                         max_features=0.5), n_estimators = 50, learning_rate = 0.9)\n",
    "model.fit(rescaledX,Y_train)\n",
    "rescaledValidationX = scaler.transform(X_validation)\n",
    "preds = model.predict(rescaledValidationX)\n",
    "\n",
    "print rmsle(np.exp(Y_validation), np.exp(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_dataset = read_csv('test_bikes.csv')\n",
    "test_dataset.datetime = test_dataset.datetime.apply(pd.to_datetime)\n",
    "test_dataset['year'] = test_dataset.datetime.apply(lambda x : x.year)\n",
    "test_dataset['month'] = test_dataset.datetime.apply(lambda x : x.month)\n",
    "test_dataset['hour'] = test_dataset.datetime.apply(lambda x : x.hour)\n",
    "test_dataset['dayofweek'] = test_dataset.datetime.apply(lambda x : x.dayofweek)\n",
    "X_test = test_dataset[test_dataset.columns[1:]].values\n",
    "scaler_test = StandardScaler().fit(X)\n",
    "rescaled_test = scaler_test.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#this gave me the best result on leaderboard (0.39888)\n",
    "scaler = StandardScaler().fit(X)\n",
    "rescaledX = scaler.transform(X)\n",
    "model = GradientBoostingRegressor(random_state=seed, n_estimators = 2000, learning_rate = 0.09,  max_features=0.5)\n",
    "model.fit(rescaledX,Y)\n",
    "rescaledTestX = scaler.transform(X_test)\n",
    "preds = model.predict(rescaledTestX)\n",
    "preds = np.exp(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(X)\n",
    "rescaledX = scaler.transform(X)\n",
    "model = RandomForestRegressor(random_state=seed, n_estimators = 2000, max_depth = 50, max_features=0.8)\n",
    "model.fit(rescaledX,Y)\n",
    "rescaledTestX = scaler.transform(X_test)\n",
    "preds = model.predict(rescaledTestX)\n",
    "preds = np.exp(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(X)\n",
    "rescaledX = scaler.transform(X)\n",
    "model = ExtraTreesRegressor(random_state=seed,  n_estimators = 1500, oob_score=True, bootstrap=True)\n",
    "model.fit(rescaledX,Y)\n",
    "rescaledTestX = scaler.transform(X_test)\n",
    "preds = model.predict(rescaledTestX)\n",
    "preds = np.exp(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(X)\n",
    "rescaledX = scaler.transform(X)\n",
    "model = AdaBoostRegressor(random_state=seed,base_estimator = GradientBoostingRegressor(random_state=seed, n_estimators = 100, \n",
    "                         max_features=0.5), n_estimators = 50, learning_rate = 0.9)\n",
    "model.fit(rescaledX,Y)\n",
    "rescaledTestX = scaler.transform(X_test)\n",
    "preds = model.predict(rescaledTestX)\n",
    "preds = np.exp(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64.3972335106\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.891941</td>\n",
       "      <td>2011-01-20 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.640564</td>\n",
       "      <td>2011-01-20 01:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.737563</td>\n",
       "      <td>2011-01-20 02:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.112728</td>\n",
       "      <td>2011-01-20 03:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.731296</td>\n",
       "      <td>2011-01-20 04:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8.324127</td>\n",
       "      <td>2011-01-20 05:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>27.340020</td>\n",
       "      <td>2011-01-20 06:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>83.036308</td>\n",
       "      <td>2011-01-20 07:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>191.000000</td>\n",
       "      <td>2011-01-20 08:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>102.853476</td>\n",
       "      <td>2011-01-20 09:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>50.567875</td>\n",
       "      <td>2011-01-20 10:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>54.819693</td>\n",
       "      <td>2011-01-20 11:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>65.756865</td>\n",
       "      <td>2011-01-20 12:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>64.397234</td>\n",
       "      <td>2011-01-20 13:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>59.841647</td>\n",
       "      <td>2011-01-20 14:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         count            datetime\n",
       "0    11.891941 2011-01-20 00:00:00\n",
       "1     4.640564 2011-01-20 01:00:00\n",
       "2     2.737563 2011-01-20 02:00:00\n",
       "3     2.112728 2011-01-20 03:00:00\n",
       "4     1.731296 2011-01-20 04:00:00\n",
       "5     8.324127 2011-01-20 05:00:00\n",
       "6    27.340020 2011-01-20 06:00:00\n",
       "7    83.036308 2011-01-20 07:00:00\n",
       "8   191.000000 2011-01-20 08:00:00\n",
       "9   102.853476 2011-01-20 09:00:00\n",
       "10   50.567875 2011-01-20 10:00:00\n",
       "11   54.819693 2011-01-20 11:00:00\n",
       "12   65.756865 2011-01-20 12:00:00\n",
       "13   64.397234 2011-01-20 13:00:00\n",
       "14   59.841647 2011-01-20 14:00:00"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_preds = preds\n",
    "print preds[13]\n",
    "for i in range(len(new_preds)):\n",
    "    if math.modf(max(0, new_preds[i]))[0]>0.9:\n",
    "        new_preds[i] = math.modf(max(0, new_preds[i]))[1]+1\n",
    "submission = pd.DataFrame({\n",
    "        \"datetime\": test_dataset[\"datetime\"],\n",
    "        \"count\": [x for x in new_preds]\n",
    "    })\n",
    "submission.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission.to_csv('bike_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "AdaBoostRegressor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ExtraTreesRegressor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GradientBoostingRegressor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RandomForestRegressor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
